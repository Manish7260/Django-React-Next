{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2136fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5e9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7a419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Ravi and Raju are the best friends from school days.They wanted to go for a world tour and \n",
    "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
    "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf77a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33ee3f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ravi and Raju are the best friends from school days.They wanted to go for a world tour and \n",
       "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
       "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd833fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7fb2c28f3a00>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7fb2c28f2f80>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7fb2c26dfbc0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7fb2c2c95540>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7fb2c2c81400>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7fb2c26dec00>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b39874b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "800fd397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proper Nouns:  [Raju, Paris, London, Dubai, Rome, Mohan, Hyderabad]\n",
      "Count:  7\n"
     ]
    }
   ],
   "source": [
    "propn = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_==\"PROPN\":\n",
    "        propn.append(token)\n",
    "print('Proper Nouns: ',propn)\n",
    "print('Count: ', len(propn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fc13023",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''The Top 5 companies in USA are Tesla, Walmart, Amazon, Microsoft, Google and the top 5 companies in \n",
    "India are Infosys, Reliance, HDFC Bank, Hindustan Unilever and Bharti Airtel'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f2d7f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country :  [Tesla, Walmart, Amazon, Microsoft, Google, Infosys, Reliance, HDFC Bank, Hindustan Unilever, Bharti]\n",
      "Count :  10\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "org = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ ==\"ORG\":\n",
    "        org.append(ent)\n",
    "print('Country : ',org)\n",
    "print('Count : ', len(org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14acc4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m537.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/logistic/anaconda3/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: joblib in /home/logistic/anaconda3/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /home/logistic/anaconda3/lib/python3.10/site-packages (from nltk) (8.0.4)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.4/770.4 kB\u001b[0m \u001b[31m132.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb06411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
